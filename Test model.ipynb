{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a66651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "log_dir = './logs/embedding/'\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "hero_path = os.path.join(data_dir, 'hero_names.json')\n",
    "\n",
    "embedding_size=64\n",
    "dropout_rate=0\n",
    "activation='tanh'\n",
    "n_hidden_predictor=128\n",
    "learning_rate=1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hero_path, 'r') as file:\n",
    "    hero_names = json.load(file)\n",
    "\n",
    "labeled_data = pd.read_csv(train_path)\n",
    "no_winner = labeled_data['radiant_win'].isna()\n",
    "labeled_data = labeled_data[~no_winner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ad335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hero names json to be keyed on id\n",
    "hero_id_info = {}\n",
    "for name, hero_dict in hero_names.items():\n",
    "    this_id = hero_dict['id']\n",
    "    hero_id_info[this_id] = hero_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd42af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test/splits from match data\n",
    "n_data = len(labeled_data)\n",
    "\n",
    "random = np.random.RandomState(seed=116)\n",
    "shuffled_rows = np.arange(n_data)\n",
    "random.shuffle(shuffled_rows, )\n",
    "\n",
    "train_frac = 0.8\n",
    "validate_frac = 0.1\n",
    "n_train = int(train_frac * n_data)\n",
    "n_val = int(validate_frac * n_data)\n",
    "train_rows = shuffled_rows[:n_train]\n",
    "val_rows = shuffled_rows[n_train:n_train+n_val]\n",
    "\n",
    "train_data = labeled_data.iloc[train_rows, :]\n",
    "val_data = labeled_data.iloc[val_rows, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(tf.keras.Model):\n",
    "    def __init__(self, pool_size=123, embedding_size=32, team_size=5,\n",
    "                 n_hidden_predictor=128, dropout_rate=0.1, activation='tanh'):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(pool_size, embedding_size,\n",
    "                                                   input_length=team_size)\n",
    "\n",
    "        self.predictor = tf.keras.Sequential(\n",
    "            [\n",
    "             tf.keras.layers.InputLayer(input_shape=(embedding_size*2 + 2,)),\n",
    "             tf.keras.layers.Dropout(dropout_rate),\n",
    "             tf.keras.layers.Dense(units=n_hidden_predictor, activation=activation),\n",
    "             tf.keras.layers.Dense(units=n_hidden_predictor, activation=activation),\n",
    "             tf.keras.layers.Dense(units=1, activation=tf.nn.sigmoid)\n",
    "            ]\n",
    "            )\n",
    "        return\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        radiant, dire, radiant_wr, dire_wr = inputs\n",
    "\n",
    "        radiant_embedding = self.embedding(radiant)\n",
    "        dire_embedding = self.embedding(dire)\n",
    "\n",
    "        radiant_embedding_sum = tf.reduce_sum(radiant_embedding, axis=1)\n",
    "        dire_embedding_sum = tf.reduce_sum(dire_embedding, axis=1)\n",
    "\n",
    "        pred_inputs = tf.concat((radiant_embedding_sum, dire_embedding_sum, radiant_wr, dire_wr), axis=-1)\n",
    "        prediction = self.predictor(pred_inputs)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "def get_win_rates(train_radiant, train_dire, train_y, n_train):\n",
    "    # Calculate historical winrates:\n",
    "    win_counts = defaultdict(lambda: 0)\n",
    "    game_counts = defaultdict(lambda: 0)\n",
    "    for row in range(n_train):\n",
    "        radiant = train_radiant.iloc[row, :]\n",
    "        dire = train_dire.iloc[row, :]\n",
    "        radiant_win = train_y.iloc[row]\n",
    "\n",
    "        for hero in radiant:\n",
    "            game_counts[hero] += 1\n",
    "        for hero in dire:\n",
    "            game_counts[hero] += 1\n",
    "\n",
    "        if radiant_win:\n",
    "            team = radiant\n",
    "        else:\n",
    "            team = dire\n",
    "\n",
    "        for hero in team:\n",
    "            win_counts[hero] += 1\n",
    "\n",
    "    win_rates = {}\n",
    "    for hero in win_counts.keys():\n",
    "        win_rates[hero] = win_counts[hero] / game_counts[hero]\n",
    "\n",
    "    return win_rates\n",
    "\n",
    "\n",
    "def get_heroes_and_winner(df):\n",
    "    radiant_cols = [f'r{idx}_hero' for idx in range(1,6)]\n",
    "    dire_cols = [f'd{idx}_hero' for idx in range(1,6)]\n",
    "\n",
    "\n",
    "    # make id's start at 0\n",
    "    radiant_heroes = df[radiant_cols] - 1\n",
    "    dire_heroes = df[dire_cols] - 1\n",
    "    winners = df['radiant_win']\n",
    "\n",
    "    return radiant_heroes, dire_heroes, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_radiant, train_dire, train_y = get_heroes_and_winner(train_data)\n",
    "val_radiant, val_dire, val_y = get_heroes_and_winner(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc539109",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rates = get_win_rates(train_radiant, train_dire, train_y, n_train)\n",
    "\n",
    "# Feature of average team winrate\n",
    "\n",
    "radiant_avg_wr = np.zeros(n_train)\n",
    "dire_avg_wr = np.zeros(n_train)\n",
    "val_radiant_wr = np.zeros(n_val)\n",
    "val_dire_wr = np.zeros(n_val)\n",
    "\n",
    "for row in range(n_train):\n",
    "    radiant = train_radiant.iloc[row, :]\n",
    "    dire = train_dire.iloc[row, :]\n",
    "\n",
    "    radiant_winrates = [win_rates[hero] for hero in radiant]\n",
    "    dire_winrates = [win_rates[hero] for hero in dire]\n",
    "\n",
    "    radiant_avg = np.mean(radiant_winrates)\n",
    "    dire_avg = np.mean(dire_winrates)\n",
    "\n",
    "    radiant_avg_wr[row] = radiant_avg\n",
    "    dire_avg_wr[row] = dire_avg\n",
    "\n",
    "for row in range(n_val):\n",
    "    radiant = val_radiant.iloc[row, :]\n",
    "    dire = val_dire.iloc[row, :]\n",
    "\n",
    "    radiant_winrates = [win_rates[hero] for hero in radiant]\n",
    "    dire_winrates = [win_rates[hero] for hero in dire]\n",
    "\n",
    "    radiant_avg = np.mean(radiant_winrates)\n",
    "    dire_avg = np.mean(dire_winrates)\n",
    "\n",
    "    val_radiant_wr[row] = radiant_avg\n",
    "    val_dire_wr[row] = dire_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aee4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_hero = min(win_rates, key=win_rates.get)\n",
    "best_hero = max(win_rates, key=win_rates.get)\n",
    "print(f'Best hero is {hero_id_info[best_hero][\"localized_name\"]} with a winrate of {100*win_rates[best_hero]:.2f}%')\n",
    "print(f'Worst hero is {hero_id_info[worst_hero][\"localized_name\"]} with a winrate of {100*win_rates[worst_hero]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f461334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingModel(pool_size=112, embedding_size=embedding_size, dropout_rate=dropout_rate,\n",
    "                           n_hidden_predictor=n_hidden_predictor, activation=activation)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "csv_logs = os.path.join(log_dir, 'metrics.csv')\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "             tf.keras.callbacks.CSVLogger(csv_logs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2746eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[tf.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c868ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[tf.cast(train_radiant, dtype=tf.int32), tf.cast(train_dire, dtype=tf.int32),\n",
    "             tf.cast(radiant_avg_wr, dtype=tf.float32), tf.cast(dire_avg_wr, dtype=tf.float32)],\n",
    "          y=tf.cast(train_y.astype(int), dtype=tf.float32),\n",
    "          callbacks=callbacks, shuffle=True,\n",
    "          batch_size=batch_size, epochs=10000,\n",
    "          validation_data=\n",
    "          ([tf.cast(val_radiant, dtype=tf.int32), tf.cast(val_dire, dtype=tf.int32),\n",
    "            tf.cast(val_radiant_wr, dtype=tf.float32), tf.cast(val_dire_wr, dtype=tf.float32)],\n",
    "           tf.cast(val_y.astype(int), dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d79ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "  for id in range(1,113):\n",
    "    if id in hero_id_info.keys():\n",
    "        hero_name = hero_id_info[id]['localized_name']\n",
    "        f.write(f'{hero_name}\\n')\n",
    "    else:\n",
    "        f.write('Unknown\\n')\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(model.embedding.get_weights()[0])\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72484ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef21ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b3ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
